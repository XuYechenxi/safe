# Consistency Model with CLIP - Image Generation Dependencies

# Core Dependencies
numpy>=1.21.0,<2.0.0  # gradio requires numpy 1.x version
Pillow>=9.0.0
scikit-learn>=1.5.0  # use newer version with pre-built wheels to avoid compilation
requests>=2.27.0

# Machine Learning
torch>=1.10.0
torchvision>=0.11.0
transformers>=4.17.0
sentence-transformers>=2.2.0  # for semantic consistency detection
diffusers>=0.21.0  # for Stable Diffusion and LoRA support (required for all models)
peft>=0.3.0  # for LoRA weight loading (optional, for ITSC-GAN model, fallback if diffusers doesn't support)

# Consistency Model Dependencies
blobfile>=1.0.5
tqdm>=4.62.0
scipy>=1.7.0
pandas>=1.3.0
Cython>=0.29.0
piq==0.7.0
joblib>=1.0.0  # newer version has pre-built wheels
albumentations>=0.4.3,<1.0.0  # use compatible version range
lmdb>=1.0.0
mpi4py>=3.0.0
einops>=0.6.0  # for attention mechanisms
# flash-attn==0.2.8  # requires CUDA environment, comment out for CPU mode
# To use flash-attn (requires CUDA):
# pip install flash-attn --no-build-isolation

# CLIP (OpenAI)
# Note: Install CLIP from git: pip install git+https://github.com/openai/CLIP.git
# Or use: clip @ git+https://github.com/openai/CLIP.git

# Web Interface
gradio>=3.0.0,<4.0.0  # ensure compatibility with numpy 1.x

# Database
sqlalchemy>=1.4.0

# Utility
python-dotenv>=0.19.0
